{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRd4nT-tu2mT",
        "outputId": "990936ae-1639-4927-b8f1-db2782ad5701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ntscraper\n",
            "  Downloading ntscraper-0.3.13-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ntscraper) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from ntscraper) (4.12.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from ntscraper) (4.9.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->ntscraper) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ntscraper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ntscraper) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ntscraper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ntscraper) (2024.2.2)\n",
            "Installing collected packages: ntscraper\n",
            "Successfully installed ntscraper-0.3.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing instances:  36%|███▋      | 28/77 [00:29<00:17,  2.76it/s]"
          ]
        }
      ],
      "source": [
        "!pip install ntscraper\n",
        "import tweepy\n",
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "from wordcloud import WordCloud\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "from ntscraper import Nitter\n",
        "scraper = Nitter(log_level = 1,skip_instance_check = False)\n",
        "tweets = scraper.get_tweets(\"BJP4India\",mode = \"user\",number = 100)\n",
        "from pprint import pprint\n",
        "pprint(tweets)\n",
        "tweets.keys()\n",
        "tweets['tweets']\n",
        "\n",
        "\n",
        "data ={\n",
        "    'link':[],\n",
        "    'text':[],\n",
        "    'user':[],\n",
        "    'likes':[],\n",
        "    'quotes':[],\n",
        "    'retweets':[],\n",
        "    'comments':[]\n",
        "}\n",
        "\n",
        "for tweet in tweets['tweets']:\n",
        "  data['link'].append(tweet['link'])\n",
        "  data['text'].append(tweet['text'])\n",
        "  data['user'].append(tweet['user'])\n",
        "  data['likes'].append(tweet['stats']['likes'])\n",
        "  data['quotes'].append(tweet['stats']['quotes'])\n",
        "  data['retweets'].append(tweet['stats']['retweets'])\n",
        "  data['comments'].append(tweet['stats']['comments'])\n",
        "\n",
        "import pandas as pd\n",
        "df =pd.DataFrame(data)\n",
        "df.head()\n",
        "\n",
        "\n",
        "#Data Cleaning is required\n",
        "# Create a function\n",
        "def cleanTxt(text):\n",
        "  text=re.sub(r'@[A-Za-z0-9]+','',text) # removes @mentions text=re.sub(r'#', '', text)\n",
        "  text=re.sub(r'RT[\\s]+','',text)\n",
        "  text=re.sub(r'https?:\\/\\/\\S+', '',text)\n",
        "  return text\n",
        "df['text']= df['text'].apply(cleanTxt)\n",
        "\n",
        "#show cleaned data\n",
        "df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def getSubjectivity(text):\n",
        "  return TextBlob(text).sentiment.subjectivity\n",
        "\n",
        "def getPolarity(text):\n",
        "  return TextBlob(text).sentiment.polarity\n",
        "\n",
        "#Create 2 more columns to store subjectivity and polarity\n",
        "df['Subjectivity'] = df['text'].apply(getSubjectivity)\n",
        "df['Polarity']= df['text'].apply(getPolarity)\n",
        "\n",
        "#Show the new data frames with new columns\n",
        "df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Word Cloud Plotting ,\n",
        "allWords =' '.join([twts for twts in df['text']])\n",
        "wordCloud = WordCloud(width =500, height=300, random_state=21, max_font_size=119).generate(allWords)\n",
        "plt.imshow(wordCloud, interpolation =\"bilinear\")\n",
        "plt.axis('off')\n",
        "plt.show\n",
        "\n",
        "\n",
        "\n",
        "#Create function to compute negate , neutral and positive analysis\n",
        "def getAnalysis(score):\n",
        "  if score < 0:\n",
        "    return 'Negative'\n",
        "  elif score == 0:\n",
        "    return 'Neutral'\n",
        "  else:\n",
        "    return 'Positive'\n",
        "df['Analysis'] =df['Polarity'].apply(getAnalysis)\n",
        "\n",
        "#Show dataframe\n",
        "df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Print all positive tweets\n",
        "j=1\n",
        "sortedDF= df.sort_values(by=['Polarity'])\n",
        "for i in range(0, sortedDF.shape[0]):\n",
        "  if (sortedDF['Analysis'][i]=='Positive'):\n",
        "    print(str(j)+')' +sortedDF['text'][i])\n",
        "    print()\n",
        "    j=j+1\n",
        "\n",
        "\n",
        "\n",
        "#Print all Negative tweets\n",
        "j=1\n",
        "sortedDF= df.sort_values(by=['Polarity'])\n",
        "for i in range(0, sortedDF.shape[0]):\n",
        "  if (sortedDF['Analysis'][i]=='Negative'):\n",
        "    print(str(j)+')' +sortedDF['text'][i])\n",
        "    print()\n",
        "    j=j+1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Print all neutral tweets\n",
        "j=1\n",
        "sortedDF= df.sort_values(by=['Polarity'])\n",
        "for i in range(0, sortedDF.shape[0]):\n",
        "  if (sortedDF['Analysis'][i]=='Neutral'):\n",
        "    print(str(j)+')' +sortedDF['text'][i])\n",
        "    print()\n",
        "    j=j+1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Plot Polarity and Subjectivity\n",
        "plt.figure(figsize=(8,6))\n",
        "for i in range(0,df.shape[0]):\n",
        "  plt.scatter(df['Polarity'][i], df['Subjectivity'][i], color='Blue')\n",
        "plt.title(\"Sentiment Analysis\")\n",
        "plt.xlabel('Polarity')\n",
        "plt.ylabel('Subjectivity')\n",
        "plt.show()\n"
      ]
    }
  ]
}